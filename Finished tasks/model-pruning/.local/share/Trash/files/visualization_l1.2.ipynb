{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import the libraries\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import gif\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "%matplotlib inline\n",
                "from sklearn.metrics import mean_squared_error\n",
                "import tensorflow as tf\n",
                "np.random.seed(0)\n",
                "tf.random.set_seed(0)\n",
                "from tensorflow.keras.layers import Input,Dense\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras import optimizers\n",
                "from tensorflow.keras import regularizers\n",
                "from sklearn.model_selection import train_test_split\n",
                "from helper import plot_weights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use the helper code below to generate the data\n",
                "\n",
                "# Defines the number of data points to generate\n",
                "num_points = 30 \n",
                "\n",
                "# Generate predictor points (x) between 0 and 5\n",
                "x = np.linspace(0,5,num_points)\n",
                "\n",
                "# Generate the response variable (y) using the predictor points\n",
                "y = x * np.sin(x) + np.random.normal(loc=0, scale=1, size=num_points)\n",
                "\n",
                "# Split the data into train and test sets with .33 and random_state = 42\n",
                "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We will now regularise the NN with L1 regularization\n",
                "# Initialise the NN, give it a different name for the ease of reading\n",
                "\n",
                "model = Sequential(name='L1regularized')\n",
                "\n",
                "# Select the number of hidden layers \n",
                "\n",
                "n_hidden = ___\n",
                "\n",
                "# Add L1 regularization\n",
                "\n",
                "myl1_reg = ___\n",
                "\n",
                "# Add 2 hidden layers with 100 neurons each\n",
                "\n",
                "model_2.add(Dense(n_hidden,  kernel_regularizer=___, activation='tanh', input_shape=(1,)))\n",
                "model_2.add(Dense(n_hidden,  kernel_regularizer=___,activation='tanh'))\n",
                "\n",
                "# Add the output layer with one neuron \n",
                "\n",
                "model_2.add(Dense(1, kernel_regularizer=___, activation='linear'))\n",
                "\n",
                "# Compile the model\n",
                "\n",
                "model_2.compile(loss='MSE',optimizer=optimizers.Adam(learning_rate=0.01)) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "for i in range(10):  \n",
                "    model.fit(x_train, y_train,  validation_split=0.2, epochs=25, batch_size=10, verbose=0)\n",
                "    plot_weights(model,epochnum = (i+1)*50)  "
            ]
        }
    ]
}
