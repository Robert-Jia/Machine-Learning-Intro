{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import the necessary libraries\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers\n",
                "from tensorflow.keras import models\n",
                "from tensorflow.keras import optimizers\n",
                "from tensorflow.keras import regularizers\n",
                "np.random.seed(0)\n",
                "tf.random.set_seed(0)\n",
                "from helper import unregularized_model\n",
                "from tensorflow.keras.models import load_model\n",
                "from sklearn.metrics import mean_squared_error\n",
                "from sklearn.model_selection import train_test_split\n",
                "%matplotlib inline"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Implement an unregularized NN "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Call the helper function unregularized_model() to get the \n",
                "# unregularized model along with the data\n",
                "x_b, x_train, x_test, y_train, y_test, y_pred, mse = unregularized_model()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Printing the MSE of the unregularized model\n",
                "print(\"MSE of the unregularized model is\", mse)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Implement the NN with dropouts\n",
                "For dropout we build the same network with \"Dropout\" layers after each activation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_2 = models.Sequential(name='Dropout_regularized')\n",
                "\n",
                "# Hidden 5 layer with 100 neurons each (or nodes)\n",
                "# Add a dropout layer after each hidden layer with some dropout percentage\n",
                "model_2.add(layers.Dense(100, activation='relu', input_shape=(1,)))\n",
                "model_2.add(___)\n",
                "\n",
                "model_2.add(layers.Dense(100, activation='relu'))\n",
                "model_2.add(___)\n",
                "\n",
                "model_2.add(layers.Dense(100, activation='relu'))\n",
                "model_2.add(___)\n",
                "\n",
                "model_2.add(layers.Dense(100, activation='relu'))\n",
                "model_2.add(___)\n",
                "\n",
                "model_2.add(layers.Dense(100, activation='relu'))\n",
                "model_2.add(___)\n",
                "\n",
                "# Output layer with one neuron \n",
                "model_2.add(layers.Dense(1,  activation='linear'))\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compile the model with MSE as loss and Adam optimizer with learning rate as 0.001\n",
                "___\n",
                "\n",
                "# Save the history about the model after fitting on the train data\n",
                "# Use 0.2 validation split  with 1500 epochs and batch size of 10\n",
                "history_2 = ___\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Helper code to plot the data\n",
                "\n",
                "# Plot the MSE of the model\n",
                "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
                "plt.title(\"Dropout Regularized\")\n",
                "plt.semilogy(history_2.history['loss'], label='Train Loss', color='#FF9A98', linewidth=2)\n",
                "plt.semilogy(history_2.history['val_loss'],  label='Validation Loss', color='#75B594', linewidth=2)\n",
                "plt.legend()\n",
                "\n",
                "# Set the axes labels\n",
                "plt.xlabel('Epochs')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "plt.show()\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ⏸ In the trace plot above, why is the validation error lower than the training error?\n",
                "\n",
                "\n",
                "#### A. The dropout percentage is high and hence the model is underfit during validation.\n",
                "#### B. During the validation phase, the validation loss is multiplied by the percentage of dropout, hence the loss is always lower than the training loss.\n",
                "#### C. The dropout percentage is low and hence the model overfits on the validation data.\n",
                "#### D. The validation takes place in the evaluation mode of dropout where the weights are already learned."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_chow1) ###\n",
                "# Submit an answer choice as a string below \n",
                "# (eg. if you choose option A, put 'A')\n",
                "answer1 = '___'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_mse) ###\n",
                "# Predict your model on x_b (used exclusively for plotting)\n",
                "y_hat_dropout = ___\n",
                "\n",
                "# Predict your model on the test data \n",
                "y_dropout_test = ___\n",
                "\n",
                "# Compute the MSE on the test data\n",
                "mse_dropout = ___"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Print the MSE of the dropout regularized model\n",
                "print(\"MSE of the dropout regularized model is\", mse_dropout)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use the helper code to plot the predicted data\n",
                "\n",
                "# Plotting the predicted data using the L2 regularized model\n",
                "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
                "plt.plot(x_b, y_hat_dropout, label='Dropout regularized', color='black', linewidth=2)\n",
                "\n",
                "# Plotting the predicted data using the unregularized model\n",
                "plt.plot(x_b, y_pred, label = 'Unregularized model', color='#005493', linewidth=2)\n",
                "\n",
                "# Plotting the training data\n",
                "plt.plot(x_train, y_train, '.', label='Train data', markersize=15, color='#FF9A98')\n",
                "\n",
                "# Plotting the testing data\n",
                "plt.plot(x_test,y_test, '.', label='Test data', markersize=15, color='#75B594')\n",
                "\n",
                "# Set the axes labels\n",
                "plt.xlabel('X')\n",
                "plt.ylabel('Y')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ⏸ **After marking the exercise, change dropout percentage to 0.8 first and 0.2 next. Do you notice any change? Which value regularizes the neural network more?**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_chow2) ###\n",
                "# Type your answer within in the quotes given\n",
                "\n",
                "answer2 = '___'"
            ]
        }
    ]
}
