{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the predictor data\n",
    "def generate_data(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the activation. \n",
    "# The activation function used for neural network is sin(x)\n",
    "def activation(a):\n",
    "     \n",
    "    return ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the partial derivate of z with respect to w\n",
    "def dzdw(w,x):\n",
    "    \n",
    "    return ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the partial derivate of w with respect to z\n",
    "def dydz(w,z):\n",
    "    \n",
    "    return ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the partial derivate of l with respect to y\n",
    "def dldy(y,y_pred):\n",
    "    \n",
    "    return ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the partial derivate of l with respect to w\n",
    "def dldw(w,x):\n",
    "    \n",
    "    # Call the previous three functions with appropriate parameters\n",
    "    ___\n",
    "    \n",
    "    return dldy*dydz*dzdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a simple neural network\n",
    "def neural_network(W, x):\n",
    "    \n",
    "    # Computing the first activation\n",
    "    a1 = np.dot(x, W[0])\n",
    "    \n",
    "    # Defining sin() as the activation function\n",
    "    fa1 = activation(a1)\n",
    "    \n",
    "    # Computing the second activation\n",
    "    a2 = np.dot(fa1,W[1])\n",
    "    \n",
    "    # Defining sin() as the activation function\n",
    "    y = activation(a2)\n",
    "    \n",
    "    return a1,a2,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the predictor and response data \n",
    "x = np.linspace(-5,5,1000).reshape(-1,1)\n",
    "y = generate_data(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the weights \n",
    "np.random.seed(310)\n",
    "W = [np.random.randn(1, 1), np.random.randn(1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the helper code below to plot the true data and the predictions of your neural network\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.plot(x,generate_data(x),label = 'True Function',color='darkblue',linewidth=2)\n",
    "ax.plot(x,neural_network(W,x)[2],label = 'Neural Network Predictions',color='#9FC131FF',linewidth=2)\n",
    "ax.set_xlabel('$x$',fontsize=14)\n",
    "ax.set_ylabel('$y$',fontsize=14)\n",
    "ax.legend(fontsize=14, loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ge the predicted response, and the two activations of the network\n",
    "a1, a2, y_pred = neural_network(W,x)\n",
    "\n",
    "# Compute the gradient of the loss function with respect to weight\n",
    "# Call the previous functions appropriately to compute this value\n",
    "dldw = ___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The gradient of the loss function is\", dldw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
