{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helper import unregularized_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement an unregularized NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the helper function to get the unregularized model along with the data\n",
    "x_b, x_train, x_test, y_train, y_test, y_pred = unregularized_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚è∏ Based on the trace plot, which patience value would you most likely choose?\n",
    "\n",
    "\n",
    "#### A. 0-5\n",
    "#### B. 10-15\n",
    "#### C. 20-25\n",
    "#### D. 35-40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow1) ###\n",
    "# Submit an answer choice as a string below (eg. if you choose option A, put 'A')\n",
    "answer1 = '___'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement previous NN with early stopping \n",
    "For early stopping we build the same network but then we implement early stopping using callbacks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building an unregularized NN with early stopping. \n",
    "# Initialise the NN, give it an appropriate name for the ease of reading\n",
    "# The FCNN has 5 layers, each with 100 nodes\n",
    "model_2 = models.Sequential(name='EarlyStopping')\n",
    "\n",
    "# Add 5 hidden layers with 100 neurons each \n",
    "# tanh is the activation for the first layer\n",
    "# relu is the activation for all other layers\n",
    "model_2.add(layers.Dense(100,  activation='tanh', input_shape=(1,)))\n",
    "model_2.add(layers.Dense(100,  activation='relu'))\n",
    "model_2.add(layers.Dense(100,  activation='relu'))\n",
    "model_2.add(layers.Dense(100,  activation='relu'))\n",
    "model_2.add(layers.Dense(100,  activation='relu'))\n",
    "\n",
    "# Add the output layer with one neuron \n",
    "model_2.add(layers.Dense(1,  activation='linear'))\n",
    "\n",
    "# View the model summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the keras early stopping callback with patience value of your choosing while monitoring the loss\n",
    "callback = ___\n",
    "\n",
    "# Compile the model with MSE as loss and Adam optimizer with learning rate as 0.001\n",
    "___\n",
    "\n",
    "# Save the history about the model after fitting on the train data\n",
    "# Use 0.2 validation split with 1500 epochs and batch size of 10\n",
    "# Use the callback for early stopping here\n",
    "history_2 = ___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to plot the data\n",
    "# Plot the MSE of the model\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "plt.title(\"Early stop model\")\n",
    "plt.semilogy(history_2.history['loss'], label='Train Loss', color='#FF9A98', linewidth=2)\n",
    "plt.semilogy(history_2.history['val_loss'],  label='Validation Loss', color='#75B594', linewidth=2)\n",
    "plt.legend()\n",
    "\n",
    "# Set the axes labels\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Log MSE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the early stop implemented model above to predict for x_b (used exclusively for plotting)\n",
    "y_early_stop_pred = ___\n",
    "\n",
    "# Use the model above to predict on the test data\n",
    "y_earl_stop_pred_test = ___\n",
    "\n",
    "# Compute the test MSE by predicting on the test data\n",
    "mse_es = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the helper code to plot the predicted data\n",
    "\n",
    "# Plotting the predicted data using the L2 regularized model\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "plt.plot(x_b, y_early_stop_pred, label='Early stop regularized model', color='black', linewidth=2)\n",
    "\n",
    "# Plotting the predicted data using the unregularized model\n",
    "plt.plot(x_b, y_pred, label = 'Unregularized model', color='#005493', linewidth=2)\n",
    "\n",
    "# Plotting the training data\n",
    "plt.plot(x_train,y_train, '.', label='Train data', markersize=15, color='#FF9A98')\n",
    "\n",
    "# Plotting the testing data\n",
    "plt.plot(x_test,y_test, '.', label='Test data', markersize=15, color='#75B594')\n",
    "\n",
    "# Set the axes labels\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mindchow üç≤\n",
    "\n",
    "**After marking change the patience parameter once to 2 and once to 100 in the early stopping callback with the same data. Do you notice any change? While value is more efficient?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow6) ###\n",
    "# Type your answer within in the quotes given\n",
    "\n",
    "answer2 = '___'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
