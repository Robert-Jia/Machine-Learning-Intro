{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gif\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "from tensorflow.keras.layers import Input,Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the helper code below to generate the data\n",
    "\n",
    "# Defines the number of data points to generate\n",
    "num_points = 30 \n",
    "\n",
    "# Generate predictor points (x) between 0 and 5\n",
    "x = np.linspace(0,5,num_points)\n",
    "\n",
    "# Generate the response variable (y) using the predictor points\n",
    "y = x * np.sin(x) + np.random.normal(loc=0, scale=1, size=num_points)\n",
    "\n",
    "# Generate data of the true function y = x*sin(x) \n",
    "# x_b will be used for all predictions below \n",
    "x_b = np.linspace(0,5,100)\n",
    "y_b = x_b*np.sin(x_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets with .33 and random_state = 42\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now regularise the NN with L1 regularization\n",
    "# Initialise the NN, give it a different name for the ease of reading\n",
    "def make_model():    \n",
    "    model_2 = Sequential(name='L1regularized')\n",
    "\n",
    "    n_hidden = 50\n",
    "    # Add L1 regularization\n",
    "    myl1_reg = regularizers.l1(0.01) \n",
    "\n",
    "    # Add 5 hidden layers with 100 neurons each\n",
    "    model_2.add(Dense(n_hidden,  kernel_regularizer=myl1_reg, activation='tanh', input_shape=(1,)))\n",
    "    model_2.add(Dense(n_hidden,  kernel_regularizer=myl1_reg,activation='tanh'))\n",
    "\n",
    "    # Add the output layer with one neuron \n",
    "    model_2.add(Dense(1, kernel_regularizer=myl1_reg, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model_2.compile(loss='MSE',optimizer=optimizers.Adam(learning_rate=0.01)) \n",
    "    return model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gif.frame\n",
    "def plot_weights(mlp,epochnum=0):\n",
    "    n_hidden = 50\n",
    "    weights = {}\n",
    "    for i in range(0,5,2):\n",
    "        weights[i] = mlp.get_weights()[i]\n",
    "    df = pd.DataFrame(columns= ['Layer 1','Layer 2','Layer 3','y'])\n",
    "    df['Layer 1'] = np.array(list(weights[0].flatten())*n_hidden).reshape(n_hidden,n_hidden).T.reshape(n_hidden**2,)\n",
    "    df['Layer 2'] = weights[2].flatten()\n",
    "    df['Layer 3'] = list(weights[4].flatten())*n_hidden\n",
    "    df.y = 'Weights'\n",
    "    with plt.xkcd(scale=0.3):\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        plt.rcParams.update({'font.size': 16})\n",
    "        numweights = df[(df['Layer 1'].abs() > 0.1) & (df['Layer 2'].abs() > 0.1)].shape[0]\n",
    "        pd.plotting.parallel_coordinates(df[(df['Layer 1'].abs() > 0.1) & (df['Layer 2'].abs() > 0.1)], \"y\",\n",
    "                                         color=[\"#1C758A\"],\n",
    "                                         cols = ['Layer 1','Layer 2','Layer 3'],\n",
    "                                         alpha=0.8,lw=3 ) \n",
    "        \n",
    "        plt.title(f'{numweights} non-zero weights after {epochnum} epochs ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "model = make_model()\n",
    "for i in range(10):    \n",
    "    model.fit(x_train, y_train,  validation_split=0.2, epochs=25, batch_size=10, verbose=0)\n",
    "    frame = plot_weights(model,epochnum = (i+1)*50)\n",
    "    frames.append(frame)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif.save(frames, 'v3.gif', duration=1.25, unit=\"s\",between = \"frames\",loop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./v3.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./v3.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
